{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_new_text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKrFVyALNd5W"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQRE7O25LODV"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "import time\n",
        "from os import getcwd, listdir, mkdir, chdir\n",
        "from os.path import join\n",
        "import requests\n",
        "if 'colab' in str(get_ipython()): from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYteHT4QNhTO"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLbp4xqyjiXN"
      },
      "source": [
        "seed = 'ยง'\n",
        "#seed = 'Operators are required to '\n",
        "#seed = 'In case of emergency, the pilots must '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI8zRSCf_Fmq"
      },
      "source": [
        "length_generated_text = 10000\n",
        "model_filename = 'model___run__2021-03-25__17-42-59___Stateful_GRU_LN_encoding_dense.h5'\n",
        "tokenizer_filename = 'tokenizer___run__2021-03-25__17-42-59___Stateful_GRU_LN_encoding_dense.json'\n",
        "model_directory = 'models'\n",
        "model_url = 'https://github.com/fabio-a-oliveira/14-CFR-FAA/blob/main/models/model___run__2021-03-25__17-42-59___Stateful_GRU_LN_encoding_dense.h5?raw=true'\n",
        "tokenizer_url = 'https://github.com/fabio-a-oliveira/14-CFR-FAA/blob/main/models/tokenizer___run__2021-03-25__17-42-59___Stateful_GRU_LN_encoding_dense.json?raw=true'\n",
        "\n",
        "generated_text_filename = time.strftime(\"generated_text___\" + str(length_generated_text) + \"_chars__%Y-%m-%d__%H-%M-%S\")\n",
        "generated_text_directory = 'generated_text'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV7UYZ3-Np49"
      },
      "source": [
        "# Functions and custom classes definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX_LkPU9_VUh"
      },
      "source": [
        "class LN_GRU_Cell(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=\"tanh\", dropout=0, recurrent_dropout=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.recurrent_dropout = recurrent_dropout\n",
        "        self.state_size = units\n",
        "        self.output_size = units\n",
        "        self.GRU_cell = keras.layers.GRUCell(units, dropout=dropout, recurrent_dropout=recurrent_dropout, activation=None)\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "        self.activation = keras.activations.get(activation)\n",
        "    def call(self, inputs, states):\n",
        "        outputs, new_states = self.GRU_cell(inputs, states)\n",
        "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
        "        return norm_outputs, [new_states]\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        custom_config = {'units':self.units,\n",
        "                         'dropout':self.dropout,\n",
        "                         'recurrent_dropout':self.recurrent_dropout,\n",
        "                         'activation':self.activation}\n",
        "        return {**base_config, **custom_config}\n",
        "    \n",
        "class LN_LSTM_Cell(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=\"tanh\", dropout=0, recurrent_dropout=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.recurrent_dropout = recurrent_dropout\n",
        "        self.state_size = [units, units]\n",
        "        self.output_size = units\n",
        "        self.LSTM_cell = keras.layers.LSTMCell(units, dropout=dropout, recurrent_dropout=recurrent_dropout, activation=None)\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "        self.activation = keras.activations.get(activation)\n",
        "    def call(self, inputs, states):\n",
        "        memory_states, carry_states = states\n",
        "        outputs, new_states = self.LSTM_cell(inputs, [memory_states, carry_states])\n",
        "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
        "        return norm_outputs, [new_states]\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        custom_config = {'units':self.units,\n",
        "                         'dropout':self.dropout,\n",
        "                         'recurrent_dropout':self.recurrent_dropout,\n",
        "                         'activation':self.activation}\n",
        "        return {**base_config, **custom_config}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIMMkRBK-hA5"
      },
      "source": [
        "def convert_to_inference_model(original_model, custom_objects=None):\n",
        "    original_model_json = original_model.to_json()\n",
        "    inference_model_dict = json.loads(original_model_json)\n",
        "\n",
        "    layers = inference_model_dict['config']['layers']\n",
        "    for layer in layers:\n",
        "        if 'stateful' in layer['config']:\n",
        "            layer['config']['stateful'] = True\n",
        "\n",
        "        if 'batch_input_shape' in layer['config']:\n",
        "            layer['config']['batch_input_shape'][0] = 1\n",
        "            layer['config']['batch_input_shape'][1] = None\n",
        "\n",
        "    inference_model = keras.models.model_from_json(json.dumps(inference_model_dict), custom_objects = custom_objects)\n",
        "    inference_model.set_weights(original_model.get_weights())\n",
        "\n",
        "    return inference_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeO6AS6JNsSF"
      },
      "source": [
        "# Download required files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWP8G8f2N7Tz"
      },
      "source": [
        "if model_directory not in listdir():\n",
        "    mkdir(model_directory)\n",
        "\n",
        "if model_filename not in listdir(model_directory):\n",
        "    wd = getcwd()\n",
        "    chdir(model_directory)\n",
        "    r = requests.get(model_url)\n",
        "    with open(model_filename, 'wb') as file:\n",
        "        file.write(r.content)\n",
        "    chdir(wd)\n",
        "\n",
        "if tokenizer_filename not in listdir(model_directory):\n",
        "    wd = getcwd()\n",
        "    chdir(model_directory)\n",
        "    r = requests.get(tokenizer_url)\n",
        "    with open(tokenizer_filename, 'wb') as file:\n",
        "        file.write(r.content)\n",
        "    chdir(wd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGfhkhfVNzPC"
      },
      "source": [
        "# Load model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-HpS-sDTXy5",
        "outputId": "aac67b95-9988-4fd3-d70f-1bef7743c00a"
      },
      "source": [
        "model = tf.keras.models.load_model(join(getcwd(), model_directory, model_filename),\n",
        "                                   custom_objects = {'LN_GRU_Cell':LN_GRU_Cell, 'LN_LSTM_Cell':LN_LSTM_Cell})\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Stateful_GRU_LN_encoding_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "TD_Encoding (TimeDistributed (None, None, 116)         0         \n",
            "_________________________________________________________________\n",
            "Recurrent_0 (RNN)            (None, None, 580)         1215680   \n",
            "_________________________________________________________________\n",
            "Recurrent_1 (RNN)            (None, None, 580)         2023040   \n",
            "_________________________________________________________________\n",
            "Recurrent_2 (RNN)            (None, None, 580)         2023040   \n",
            "_________________________________________________________________\n",
            "Dense (Dense)                (None, None, 116)         67396     \n",
            "=================================================================\n",
            "Total params: 5,329,156\n",
            "Trainable params: 5,329,156\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhwb2C5PTXvh"
      },
      "source": [
        "with open(join(getcwd(), model_directory, tokenizer_filename), 'rb') as file:\n",
        "    tokenizer = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3vohZ67N185"
      },
      "source": [
        "# Generate new text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "ZPbiiwO9-vR0",
        "outputId": "7ccb22a6-bd58-4e4e-f65d-fbc2fb9f29eb"
      },
      "source": [
        "inference_model = convert_to_inference_model(model, custom_objects = {'LN_GRU_Cell':LN_GRU_Cell, 'LN_LSTM_Cell':LN_LSTM_Cell})\n",
        "\n",
        "text = seed\n",
        "sequence = tokenizer.texts_to_sequences([text])\n",
        "dict_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "for i in range(length_generated_text):\n",
        "\n",
        "    if i % 1000 == 0:\n",
        "        print('Progress -- characters generated: {}/{}'.format(i, length_generated_text))\n",
        "    elif i == length_generated_text-1:\n",
        "        print('Progress -- characters generated: {}/{}'.format(length_generated_text, length_generated_text))\n",
        "\n",
        "    probs = inference_model.predict(np.array(sequence[0][-1]).reshape(1,-1,1))\n",
        "    token = np.random.choice(np.arange(dict_size), p = probs[0,-1,:])\n",
        "    sequence[0].append(token)\n",
        "\n",
        "text = tokenizer.sequences_to_texts(sequence)[0]  \n",
        "print('\\n\\nGenerated text (up to first 10000 characters):\\n')  \n",
        "print(text[0:np.min([10000, length_generated_text]):2])\n",
        "\n",
        "if generated_text_directory not in listdir():\n",
        "    mkdir(generated_text_directory)\n",
        "\n",
        "with open(join(getcwd(), generated_text_directory, generated_text_filename + '.txt'), 'w', encoding='utf-8') as file:\n",
        "    file.write(text[0::2])\n",
        "\n",
        "if 'colab' in str(get_ipython()): files.download(join(getcwd(), generated_text_directory, generated_text_filename + '.txt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress -- characters generated: 0/10000\n",
            "Progress -- characters generated: 1000/10000\n",
            "Progress -- characters generated: 2000/10000\n",
            "Progress -- characters generated: 3000/10000\n",
            "Progress -- characters generated: 4000/10000\n",
            "Progress -- characters generated: 5000/10000\n",
            "Progress -- characters generated: 6000/10000\n",
            "Progress -- characters generated: 7000/10000\n",
            "Progress -- characters generated: 8000/10000\n",
            "Progress -- characters generated: 9000/10000\n",
            "Progress -- characters generated: 10000/10000\n",
            "\n",
            "\n",
            "Generated text (up to first 10000 characters):\n",
            "\n",
            "ยง 61.113 of this part.\n",
            "(4) An applicant for an approval of its certificate to act as second in command of an aircraft operated under part 121 of this chapter, as appropriate. \n",
            "(g) Each certificate holder conducting domestic or flag operations using the airplane must be operated continuously from the surface of the earth on takeoff if applicable.\n",
            "(2) Approaches involving positioning and endroume. \n",
            "(f) The pilot in command of an aircraft under this section -  \n",
            "(1) Specified in that designation for a reserve conservation, and approach involving a flight in the United States from any point on the route of turf or one segment of the flight. \n",
            "(h) No certificate holder conducting flag operations may use any person, nor may any person serve, as a pilot in command pilot on or both of any person on board the aircraft passes threat to perform or rentalls in controlled airspace, shall provide the following:\n",
            "(1) A current standard as a biller of a parachute operation for which an air traffic control tower is directed by that portion of the flight. \n",
            "(2) For military pilots qualified, as provided under this paragraph. \n",
            "(b) That person must complete a training course for which a flight engineer is in a flight engineer, as applicable, primarily to that aircraft in the same category and class of aircraft for the category and class of aircraft for the type airplane involved.\n",
            "(2) The required knowledge test for an airline transport pilot certificate with an airplane category multiengine class rating,\n",
            "(ii) Flight proficiency;\n",
            "(ii) Preflight preparation; \n",
            "(iv) Preflight locations; \n",
            "(iii) Crew resource management and expressed in any other capacity; or \n",
            "(ii) An airplane that has a continuous plan for a Special Federal Aviation Administration carrier, provided the program manager may use those persons to serve as a pilot in command or flight engineer; and \n",
            "(3) Has flight experience requirements of this paragraph (d), except ยง 61.105(b) of this part, and each person substitutes that person's hoad and use a system and competency checks that are required to take a dispatch or flight engineer training program. The TSO holder may petition the Federal Register in accordance with the procedures in ยง 191.417. The necessary tail review is available for aerodynamic business names.\n",
            "(c) The installation of those testing is considered in accordance with ยง 60-1.3(c) of this chapter. However, any examination of the program manager's management specifications of the repair station may not conduct any operation for which temporary flight restrictions was affected by the Government departm number and the nature and extent of the effectiveness of the equipment to be confirmed [Reserved]\n",
            "(3) The name and address of each person that objects to any aircraft operated under this part. \n",
            "(b) Each letter of authorization must contain, at least the maneuvers and procedures specified in paragraph (b)(3) of this section shall be retained at the control of a light-sport aircraft may be used for compensation or hire. \n",
            "\n",
            "\n",
            "ยง 103.3   Airworthiness certificates.(a) Except as specified in paragraph (e) of this section, a person who requests an aeronautical experience with a flight or a rule of this part.\n",
            "(6) A signed statement - โInstructor, holding appropriate aircraft ratings, or completed a commercial pilot certificate when:\n",
            "(i) Multiengine airplane, other than the work performed in accordance with those requirements. \n",
            "(i) A certificated repair station must maintain the records required by paragraph (b) of this section:\n",
            "(1) Before May 26, 1995; And \n",
            "(b) Required land use cargo that are in an operable condition. \n",
            "\n",
            "\n",
            "ยง 125.377   Loading requirements: Supplemental operations.(a) Except as provided in ยงยง 121.553(a)(1) and 121.537 do. once of the following - \n",
            "(1) Fly from the airplane status consistent with approved device and approved in accordance with ยง 25.21(g), and is - \n",
            "(1) A constant amount less than one-quarter of the minimum descent altitude (for which certification is requested need not be repeated during flight to those at VNE (power-off), as viewed when looking forward along the weight, greater than 15 inches. The following conditions do restrictive that the airplane is certified to safely operate: \n",
            "(1) VSR; and\n",
            "(2) The airplane at the destination airport within approved operating limitations are also must be in effect on July 31, 1978. Except as provided in paragraph (b) of this section, each certificate holder conducting domestic operations must select clearance of the MU-2B or Type II or Type Certificate A2PC, MHI Document No. YET06249A, accepted by FSB on February 12, 2007.\n",
            "(j) All aircraft operations of U.S.-registered civil airplanes covered by this section to have a safety belt and shoulder harness who meet the requirements of ยง 171.113. \n",
            "(b) Each certificate holder described in ยง 121.360(a)(1) to substantiate 19 consecutive calendar months preceding the month of the date of examination, if - \n",
            "(i) The established noise contact point of the airport will\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5a5c3c3f-475e-43f3-83ff-e51e2816078b\", \"generated_text___10000_chars__2021-04-01__18-31-56.txt\", 10023)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}